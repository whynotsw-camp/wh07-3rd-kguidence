# app/services/chat_service.py - ë‹¤ì¤‘ ê²€ìƒ‰ íŒ¨í„´ í™•ì¥ ë²„ì „ + í¬ë§·íŒ… ê°•ì œ
from typing import Dict, Any, List, Optional
from sqlalchemy.orm import Session
import json
import os
import random
import re
import asyncio
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from qdrant_client import QdrantClient
from concurrent.futures import ThreadPoolExecutor

load_dotenv()

from app.models.conversation import Conversation  
from app.models.festival import Festival
from app.utils.openai_client import chat_with_gpt, chat_with_gpt_stream
from app.utils.prompts import (
    KPOP_FESTIVAL_QUICK_PROMPT,
    KPOP_ATTRACTION_QUICK_PROMPT,
    COMPARISON_PROMPT,
    ADVICE_PROMPT,
    RESTAURANT_QUICK_PROMPT,
    RESTAURANT_COMPARISON_PROMPT,
    RESTAURANT_ADVICE_PROMPT,
    KCONTENT_QUICK_PROMPT,
    KCONTENT_COMPARISON_PROMPT,
    KCONTENT_ADVICE_PROMPT
)

class ChatService:
    
    # ğŸ¯ ì„¤ì •ê°’ë“¤
    QDRANT_URL = os.getenv("QDRANT_URL", "http://172.17.0.1:6333")
    QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
    
    COLLECTION_NAME = "seoul-festival"
    ATTRACTION_COLLECTION = "seoul-attraction"
    RESTAURANT_COLLECTION = "seoul-restaurant"
    KCONTENT_COLLECTION = "seoul-kcontents"  # ğŸ¬ K-Content ì¶”ê°€
    
    # ğŸš€ ìºì‹±ëœ ì¸ìŠ¤í„´ìŠ¤ë“¤
    _embedding_model = None
    _qdrant_client = None
    
    # ğŸ¨ í¬ë§·íŒ… ê°•ì œ System Message - ì¶”ê°€!
    FORMATTING_SYSTEM_MESSAGE = {
        "role": "system",
        "content": """CRITICAL FORMATTING RULES - YOU MUST FOLLOW THESE:

1. NEVER write long continuous paragraphs
2. Use double line breaks (\\n\\n) between different sections
3. Keep each paragraph to 1-2 sentences maximum
4. For lists, use bullet format with â€¢ symbol
5. Add line breaks before and after bullet lists
6. ALWAYS respond in English only - no Korean characters unless specifically requested
7. When showing Korean phrases, use romanization (e.g., "annyeonghaseyo" not "ì•ˆë…•í•˜ì„¸ìš”")

Example format:
[Opening sentence with emoji]

[Key point 1 - separate paragraph]

[Key point 2 - separate paragraph]

â€¢ Bullet point 1
â€¢ Bullet point 2
â€¢ Bullet point 3

[Closing sentence]

ALWAYS structure your response this way for maximum readability!"""
    }
    
    @staticmethod
    def _get_embedding_model():
        """ì„ë² ë”© ëª¨ë¸ ì‹±ê¸€í†¤"""
        if ChatService._embedding_model is None:
            ChatService._embedding_model = OpenAIEmbeddings(model="text-embedding-ada-002")
        return ChatService._embedding_model
    
    @staticmethod
    def _get_qdrant_client():
        """Qdrant í´ë¼ì´ì–¸íŠ¸ ì‹±ê¸€í†¤"""
        if ChatService._qdrant_client is None:
            if ChatService.QDRANT_API_KEY:
                ChatService._qdrant_client = QdrantClient(
                    url=ChatService.QDRANT_URL,
                    api_key=ChatService.QDRANT_API_KEY,
                    timeout=60,
                    prefer_grpc=False
                )
                print(f"âœ… Qdrant Cloud ì—°ê²°: {ChatService.QDRANT_URL}")
            else:
                ChatService._qdrant_client = QdrantClient(
                    url=ChatService.QDRANT_URL,
                    timeout=60,
                    prefer_grpc=False
                )
                print(f"âœ… Qdrant Local ì—°ê²°: {ChatService.QDRANT_URL}")
        return ChatService._qdrant_client
    
    # ===== í†µí•©ëœ ê²€ìƒ‰ì–´ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ =====
    
    @staticmethod
    def _process_search_query(query: str, search_type: str = "attraction") -> str:
        """í†µí•© ê²€ìƒ‰ì–´ ì²˜ë¦¬ (ì „ì²˜ë¦¬ + ì •ê·œí™”) - K-Content í¬í•¨"""
        
        # 1. ë¶ˆìš©ì–´ ì œê±° (ë” ì œí•œì ìœ¼ë¡œ)
        stopwords = {"a", "an", "the", "me", "to", "introduce"}  # ğŸ”§ ì¤„ì„
        words = [w for w in query.lower().split() if w not in stopwords]
        cleaned_query = " ".join(words) if words else query
        
        # 2. ê²€ìƒ‰ì–´ ì •ê·œí™” (íƒ€ì…ë³„ ë³´ì • ê·œì¹™)
        if search_type == "kcontent":
            # K-Drama/K-Content íŠ¹í™” ë³´ì •
            corrections = {
                "crash landing on you": "ì‚¬ë‘ì˜ ë¶ˆì‹œì°©",
                "itaewon class": "ì´íƒœì› í´ë¼ì“°",
                "kingdom": "í‚¹ë¤",
                "goblin": "ë„ê¹¨ë¹„",
                "descendants of the sun": "íƒœì–‘ì˜ í›„ì˜ˆ",
                "my love from the star": "ë³„ì—ì„œ ì˜¨ ê·¸ëŒ€",
                "mom's friend's son": "ì—„ë§ˆì¹œêµ¬ì•„ë“¤",
                "filming location": "ì´¬ì˜ì§€",
                "drama location": "ë“œë¼ë§ˆ ì´¬ì˜ì§€",
                "kdrama": "í•œêµ­ ë“œë¼ë§ˆ",
                "k-drama": "í•œêµ­ ë“œë¼ë§ˆ",
                "divorce insurance": "ì´í˜¼ë³´í—˜",  # ğŸ†• ì¶”ê°€
            }
        else:
            # ì¼ë°˜ ê´€ê´‘ì§€/ë ˆìŠ¤í† ë‘ ë³´ì •
            corrections = {
                "namsan tower": "namsan seoul tower",
                "n tower": "namsan seoul tower", 
                "seoul tower": "namsan seoul tower",
                "63 building": "63ë¹Œë”©",
                "lotte tower": "lotte world tower",
                "dongdaemun": "dongdaemun design plaza",
                "myeongdong": "myeongdong shopping street",
                "gangnam": "gangnam district",
                "hongdae": "hongik university area",
                "bukchon": "bukchon hanok village",
                "insadong": "insadong cultural street",
                "itaewon": "itaewon global village",
                "korean bbq": "korean barbecue",
                "korean food": "korean restaurant",
                "chinese food": "chinese restaurant",
                "japanese food": "japanese restaurant",
                "hongdae food": "hongik university restaurant",
                "gangnam food": "gangnam district restaurant",
                "myeongdong food": "myeongdong restaurant",
            }
        
        query_lower = cleaned_query.lower()
        for wrong, correct in corrections.items():
            if wrong in query_lower:
                cleaned_query = cleaned_query.replace(wrong, correct)
                print(f"ğŸ”§ ê²€ìƒ‰ì–´ ë³´ì •: '{wrong}' â†’ '{correct}'")
        
        return cleaned_query
    
    @staticmethod
    def _expand_search_terms(query: str, search_type: str = "attraction") -> List[str]:
        """ê²€ìƒ‰ì–´ í™•ì¥ (íƒ€ì…ë³„ ë³€í˜•)"""
        variants = [query]
        query_lower = query.lower()
        
        if search_type == "kcontent":
            # K-Content ì „ìš© í™•ì¥
            if "filming" in query_lower or "location" in query_lower:
                variants.append(query.replace("filming location", "ì´¬ì˜ì§€"))
                variants.append(query.replace("location", "ì¥ì†Œ"))
            if "drama" in query_lower:
                variants.append(query.replace("drama", "ë“œë¼ë§ˆ"))
        else:
            # ì¼ë°˜ ê´€ê´‘ì§€/ë ˆìŠ¤í† ë‘ í™•ì¥
            if "seoul" not in query_lower and len(query.split()) <= 2:
                variants.extend([f"{query} seoul", f"seoul {query}"])
            
            translations = {
                "tower": "íƒ€ì›Œ", "palace": "ê¶", "temple": "ì‚¬", 
                "market": "ì‹œì¥", "park": "ê³µì›", "restaurant": "ë§›ì§‘", "food": "ìŒì‹"
            }
            
            for english, korean in translations.items():
                if english in query_lower:
                    variants.append(query.replace(english, korean).replace(english.title(), korean))
        
        return list(set(variants))
    
    @staticmethod
    def _calculate_keyword_overlap(query: str, title: str) -> float:
        """í‚¤ì›Œë“œ ê²¹ì¹˜ëŠ” ì •ë„ ê³„ì‚°"""
        query_words = set(query.lower().split())
        title_words = set(title.lower().split())
        
        overlap = len(query_words & title_words)
        total = len(query_words | title_words)
        
        return overlap / total if total > 0 else 0
    
    @staticmethod
    def _improved_search(query: str, search_type: str = "attraction") -> Optional[Dict]:
        """ê°œì„ ëœ í†µí•© ê²€ìƒ‰ ë¡œì§ (K-Content í¬í•¨)"""
        try:
            print(f"ğŸ” ê°œì„ ëœ ê²€ìƒ‰ ì‹œì‘: '{query}' (íƒ€ì…: {search_type})")
            
            # 1. ì¿¼ë¦¬ ì²˜ë¦¬ (íƒ€ì…ë³„)
            cleaned_query = ChatService._process_search_query(query, search_type)
            
            # 2. ê²€ìƒ‰ì–´ í™•ì¥ (íƒ€ì…ë³„)
            search_variants = ChatService._expand_search_terms(cleaned_query, search_type)
            print(f"ğŸ”§ ê²€ìƒ‰ ë³€í˜•ë“¤: {search_variants}")
            
            # 3. ëª¨ë“  ë³€í˜•ìœ¼ë¡œ ê²€ìƒ‰
            best_result = None
            best_score = 0
            
            qdrant_client = ChatService._get_qdrant_client()
            embedding_model = ChatService._get_embedding_model()
            
            # ì»¬ë ‰ì…˜ ì„ íƒ
            collections = {
                "restaurant": ChatService.RESTAURANT_COLLECTION,
                "attraction": ChatService.ATTRACTION_COLLECTION,
                "festival": ChatService.COLLECTION_NAME,
                "kcontent": ChatService.KCONTENT_COLLECTION  # ğŸ¬ K-Content ì¶”ê°€
            }
            collection_name = collections.get(search_type, ChatService.COLLECTION_NAME)
            
            for variant in search_variants:
                try:
                    query_embedding = embedding_model.embed_query(variant)
                    
                    search_results = qdrant_client.search(
                        collection_name=collection_name,
                        query_vector=query_embedding,
                        limit=5,
                        score_threshold=0.3,
                        with_payload=True,
                        with_vectors=False
                    )
                    
                    for result in search_results:
                        vector_score = result.score
                        
                        # íƒ€ì…ë³„ ì œëª© ì¶”ì¶œ (K-Content í•„ë“œëª… ë§¤í•‘)
                        if search_type == "restaurant":
                            title = result.payload.get("metadata", {}).get("name", "")
                        elif search_type == "kcontent":
                            metadata = result.payload.get("metadata", {})
                            drama_name = metadata.get("drama_name_ko", "")  # ğŸ”„ ë³€ê²½
                            location_name = metadata.get("location_name_en", "")  # ğŸ”„ ë³€ê²½
                            title = f"{drama_name} {location_name}"
                        else:
                            title = result.payload.get("metadata", {}).get("title", "")
                            
                        keyword_score = ChatService._calculate_keyword_overlap(cleaned_query, title)
                        combined_score = vector_score * 0.8 + keyword_score * 0.2
                        
                        if combined_score > best_score:
                            best_score = combined_score
                            best_result = result
                            print(f"âœ… ë” ì¢‹ì€ ê²°ê³¼: '{variant}' â†’ ì ìˆ˜: {combined_score:.3f}")
                
                except Exception as e:
                    print(f"âš ï¸ ë³€í˜• '{variant}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    continue
            
            # ê²°ê³¼ ë°˜í™˜ (K-ContentëŠ” ì„ê³„ê°’ 0.4, ë‚˜ë¨¸ì§€ëŠ” 0.5)
            threshold = 0.4 if search_type == "kcontent" else 0.5
            if best_result and best_score > threshold:
                return best_result
            else:
                print(f"âŒ ìœ íš¨í•œ ê²°ê³¼ ì—†ìŒ (ìµœê³  ì ìˆ˜: {best_score:.3f})")
                return None
                
        except Exception as e:
            print(f"âŒ ê°œì„ ëœ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return None

    # ===== ğŸ†• ë‹¤ì¤‘ K-Content ê²€ìƒ‰ í•¨ìˆ˜ =====
    
    @staticmethod
    def _search_multiple_kcontent(keyword: str, limit: int = 20) -> List[Dict[str, Any]]:
        """ğŸ†• K-Content ë‹¤ì¤‘ ê²€ìƒ‰ - ì¹´ë“œ í˜•íƒœ ì¶œë ¥ìš©"""
        try:
            print(f"ğŸ” ë‹¤ì¤‘ K-Content ê²€ìƒ‰ ì‹œì‘: '{keyword}' (ìµœëŒ€ {limit}ê°œ)")
            
            # 1. ì¿¼ë¦¬ ì²˜ë¦¬
            cleaned_query = ChatService._process_search_query(keyword, "kcontent")
            search_variants = ChatService._expand_search_terms(cleaned_query, "kcontent")
            print(f"ğŸ”§ ê²€ìƒ‰ ë³€í˜•ë“¤: {search_variants}")
            
            # 2. ëª¨ë“  ë§¤ì¹­ ê²°ê³¼ ìˆ˜ì§‘
            all_results = []
            seen_content_ids = set()  # ì¤‘ë³µ ì œê±°ìš©
            
            qdrant_client = ChatService._get_qdrant_client()
            embedding_model = ChatService._get_embedding_model()
            
            for variant in search_variants:
                try:
                    query_embedding = embedding_model.embed_query(variant)
                    
                    search_results = qdrant_client.search(
                        collection_name=ChatService.KCONTENT_COLLECTION,
                        query_vector=query_embedding,
                        limit=30,  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ ì„ ë³„
                        score_threshold=0.3,
                        with_payload=True,
                        with_vectors=False
                    )
                    
                    for result in search_results:
                        metadata = result.payload.get("metadata", {})
                        content_id = metadata.get("content_id", "")
                        
                        # ì¤‘ë³µ ì œê±°
                        if content_id in seen_content_ids:
                            continue
                        seen_content_ids.add(content_id)
                        
                        # ë“œë¼ë§ˆëª… ë§¤ì¹­ ì²´í¬
                        drama_name_ko = metadata.get("drama_name_ko", "")
                        drama_name_en = metadata.get("drama_name_en", "")
                        location_name = metadata.get("location_name_en", "")
                        title = f"{drama_name_ko} {location_name}"
                        
                        vector_score = result.score
                        keyword_score = ChatService._calculate_keyword_overlap(cleaned_query, title)
                        combined_score = vector_score * 0.8 + keyword_score * 0.2
                        
                        # ì„ê³„ê°’ í†µê³¼í•œ ê²°ê³¼ë§Œ í¬í•¨
                        if combined_score > 0.35:  # ë‹¤ì¤‘ ê²€ìƒ‰ì€ ì¡°ê¸ˆ ë‚®ì€ ì„ê³„ê°’
                            # ğŸ¨ ì¹´ë“œ í˜•íƒœ ë°ì´í„° ìƒì„±
                            card_data = {
                                "content_id": content_id,
                                "location_name": location_name,
                                "category": metadata.get("category_en", ""),
                                "thumbnail": metadata.get("thumbnail", ""),
                                "drama_name": drama_name_ko,
                                "drama_name_en": drama_name_en,
                                "latitude": float(metadata.get("latitude", 0)),
                                "longitude": float(metadata.get("longitude", 0)),
                                "similarity_score": combined_score,
                                "type": "kcontent"
                            }
                            all_results.append(card_data)
                            print(f"âœ… ì¶”ê°€: {location_name} ({drama_name_ko}) - ì ìˆ˜: {combined_score:.3f}")
                
                except Exception as e:
                    print(f"âš ï¸ ë³€í˜• '{variant}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    continue
            
            # ì ìˆ˜ìˆœ ì •ë ¬ í›„ ìƒìœ„ limitê°œ ë°˜í™˜
            all_results.sort(key=lambda x: x['similarity_score'], reverse=True)
            final_results = all_results[:limit]
            
            print(f"ğŸ¯ ìµœì¢… {len(final_results)}ê°œ ì¥ì†Œ ì„ ë³„ ì™„ë£Œ")
            return final_results
                
        except Exception as e:
            print(f"âŒ ë‹¤ì¤‘ K-Content ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    # ===== ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ… (íƒ€ì…ë³„) =====
    
    @staticmethod
    def _format_search_result(result, search_type: str) -> Dict[str, Any]:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ íƒ€ì…ë³„ë¡œ í¬ë§·íŒ… (K-Content í¬í•¨)"""
        if not result:
            return None
            
        metadata = result.payload.get("metadata", {})
        page_content = result.payload.get("page_content", "")
        
        if search_type == "restaurant":
            return {
                "id": str(metadata.get("restaurant_id", "")),
                "restaurant_name": metadata.get("name", ""),
                "place": metadata.get("place", ""),
                "place_en": metadata.get("place_en", ""),
                "subway": metadata.get("subway", ""),
                "description": page_content[:200] if page_content else "",
                "latitude": float(metadata.get("latitude", 0)),
                "longitude": float(metadata.get("longitude", 0)),
                "similarity_score": result.score,
                "type": "restaurant"
            }
        elif search_type == "festival":
            return {
                "festival_id": metadata.get("festival_id", metadata.get("row")),
                "title": metadata.get("title", ""),
                "filter_type": metadata.get("filter_type", ""), 
                "start_date": metadata.get("start_date", ""),
                "end_date": metadata.get("end_date", ""),
                "image_url": metadata.get("image_url", ""),
                "detail_url": metadata.get("detail_url", ""),
                "latitude": float(metadata.get("latitude", 0)) if metadata.get("latitude") else 0.0,
                "longitude": float(metadata.get("longitude", 0)) if metadata.get("longitude") else 0.0,
                "description": metadata.get("description", ""),
                "similarity_score": result.score,
                "type": "festival"
            }
        elif search_type == "kcontent":
            # ğŸ¬ K-Content í¬ë§·íŒ… (ì‹¤ì œ ì»¬ëŸ¼ëª… ì‚¬ìš©)
            return {
                "content_id": metadata.get("content_id", ""),
                "drama_name": metadata.get("drama_name_ko", ""),  # ğŸ”„ ë³€ê²½
                "drama_name_en": metadata.get("drama_name_en", ""),
                "location_name": metadata.get("location_name_en", ""),  # ğŸ”„ ë³€ê²½
                "address": metadata.get("address_en", ""),  # ğŸ”„ ë³€ê²½
                "trip_tip": metadata.get("trip_tip_en", ""),  # ğŸ”„ trip_tip_en â†’ trip_tip
                "keyword": metadata.get("keyword_en", ""),  # ğŸ”„ ë³€ê²½
                "category": metadata.get("category_en", ""),  # ğŸ”„ ë³€ê²½
                "thumbnail": metadata.get("thumbnail", ""),
                "second_image": metadata.get("second_image", ""),
                "third_image": metadata.get("third_image", ""),
                "latitude": float(metadata.get("latitude", 0)),
                "longitude": float(metadata.get("longitude", 0)),
                "similarity_score": result.score,
                "type": "kcontent"
            }
        else:  # attraction
            return {
                "attr_id": metadata.get("attr_id", ""),
                "title": metadata.get("title", ""),
                "url": metadata.get("url", ""),
                "description": metadata.get("description", ""),
                "phone": metadata.get("phone", ""),
                "hours_of_operation": metadata.get("hours_of_operation", "ìš´ì˜ì‹œê°„ ì •ë³´ ì—†ìŒ"),
                "holidays": metadata.get("holidays", ""),
                "address": metadata.get("address", ""),
                "transportation": metadata.get("transportation", ""),
                "image_urls": metadata.get("image_urls", []),
                "image_count": metadata.get("image_count", 0),
                "latitude": float(metadata.get("latitude", 0)),
                "longitude": float(metadata.get("longitude", 0)),
                "attr_code": metadata.get("attr_code", ""),
                "similarity_score": result.score,
                "type": "attraction"
            }
    
    # ===== íƒ€ì…ë³„ ê²€ìƒ‰ í•¨ìˆ˜ë“¤ =====
    
    @staticmethod
    def _search_best_restaurant(keyword: str) -> Optional[Dict[str, Any]]:
        """ë ˆìŠ¤í† ë‘ ê²€ìƒ‰"""
        result = ChatService._improved_search(keyword, "restaurant")
        return ChatService._format_search_result(result, "restaurant")
    
    @staticmethod
    def _search_best_festival(keyword: str) -> Optional[Dict[str, Any]]:
        """ì¶•ì œ ê²€ìƒ‰"""
        result = ChatService._improved_search(keyword, "festival")
        return ChatService._format_search_result(result, "festival")
    
    @staticmethod
    def _search_best_attraction(keyword: str) -> Optional[Dict[str, Any]]:
        """ê´€ê´‘ëª…ì†Œ ê²€ìƒ‰"""
        result = ChatService._improved_search(keyword, "attraction")
        return ChatService._format_search_result(result, "attraction")
    
    @staticmethod
    def _search_best_kcontent(keyword: str) -> Optional[Dict[str, Any]]:
        """ğŸ¬ K-Content ê²€ìƒ‰"""
        result = ChatService._improved_search(keyword, "kcontent")
        return ChatService._format_search_result(result, "kcontent")
    
    # ===== ë©”ì‹œì§€ ë¶„ì„ =====
    
    @staticmethod
    def _analyze_message_fast(message: str, is_kcontent_mode: bool = False) -> Dict[str, Any]:
        """ë©”ì‹œì§€ ë¶„ì„ (ğŸ”§ ë” ë„“ì€ ë‹¤ì¤‘ ê²€ìƒ‰ íŒ¨í„´)"""
        message_lower = message.lower().strip()
        print(f"\nğŸ” ì§ˆë¬¸ ë¶„ì„ ì‹œì‘: '{message}' (K-Contentëª¨ë“œ: {is_kcontent_mode})")
        
        # ìˆ˜ëŸ‰ ì¶”ì¶œ
        number_patterns = [r'(\d+)ê³³', r'(\d+)ê°œ', r'(\d+)ê°€ì§€', r'(\d+)\s*places?', r'(\d+)\s*spots?', r'(\d+)\s*locations?']
        extracted_count = None
        for pattern in number_patterns:
            match = re.search(pattern, message_lower)
            if match:
                extracted_count = int(match.group(1))
                print(f"   âœ… ìˆ˜ëŸ‰ ë°œê²¬: {extracted_count}ê°œ")
                break
        
        # ğŸ†• ë” ë„“ì€ ë‹¤ì¤‘ ê²€ìƒ‰ íŒ¨í„´ ê°ì§€
        multiple_patterns = [
            'places that appeared', 'locations that appeared', 'places from',
            'all places', 'all locations', 'filming locations',
            'places in', 'locations in', 'where', 'appeared',
            'show me', 'tell me where', 'what are the places',
            'places of', 'locations of', 'spots from', 'spots in',
            'ëª¨ë“  ì¥ì†Œ', 'ì „ì²´ ì´¬ì˜ì§€', 'ë‚˜ì˜¨ ì¥ì†Œ', 'ë“±ì¥í•œ ì¥ì†Œ', 'ì´¬ì˜ ì¥ì†Œë“¤',
            'drama', 'divorce insurance', 'places'  # ğŸ”§ ë” ì¶”ê°€
        ]
        
        has_multiple_intent = any(pattern in message_lower for pattern in multiple_patterns)
        
        # ğŸ”§ ë“œë¼ë§ˆ ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬
        drama_keywords = ['drama', 'divorce insurance', "mom's friend's son", 'appeared', 'filming', 'locations', 'places']
        has_drama = any(kw in message_lower for kw in drama_keywords)
        
        # ğŸ¯ K-Content ëª¨ë“œì´ê±°ë‚˜ ë“œë¼ë§ˆ ê´€ë ¨ì´ë©´ ë‹¤ì¤‘ ê²€ìƒ‰ í—ˆìš©
        if has_multiple_intent and (is_kcontent_mode or has_drama):
            keyword = ChatService._extract_keyword_simple(message)
            print(f"ğŸ¬ ë‹¤ì¤‘ ê²€ìƒ‰ íŠ¸ë¦¬ê±°! í‚¤ì›Œë“œ: '{keyword}'")
            return {"type": "multiple_kcontent_search", "keyword": keyword, "count": extracted_count or 20}
        
        # ë¹„êµ ì§ˆë¬¸ ê°ì§€
        comparison_patterns = [' vs ', 'vs.', ' versus ', 'which one', 'which is better', 'compare']
        if any(p in message_lower for p in comparison_patterns):
            return {"type": "comparison", "keyword": message, "count": extracted_count}
        
        # ì¡°ì–¸/íŒ ì§ˆë¬¸ ê°ì§€
        advice_patterns = ['tip', 'tips', 'advice', 'íŒ', 'ì¡°ì–¸', 'how to', 'ì–´ë–»ê²Œ', 'ë°©ë²•', 'what should i know', 'ì•Œì•„ì•¼', 'ì¤€ë¹„', 'etiquette', 'ì—í‹°ì¼“']
        
        if is_kcontent_mode:
            # K-Content ëª¨ë“œ: ë“œë¼ë§ˆ ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬
            drama_keywords = ['drama', 'filming', 'location', 'scene', 'ë“œë¼ë§ˆ', 'ì´¬ì˜ì§€', 'ì¥ë©´', 'ì¥ì†Œ']
            has_drama = any(kw in message_lower for kw in drama_keywords)
            has_advice = any(kw in message_lower for kw in advice_patterns)
            
            if has_advice and not has_drama:
                return {"type": "general_advice", "keyword": message, "count": extracted_count}
        else:
            # ì¼ë°˜ ëª¨ë“œ: ì¥ì†Œ ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬
            place_keywords = ['palace', 'temple', 'tower', 'museum', 'park', 'ê¶', 'ì‚¬ì°°', 'íƒ€ì›Œ', 'ë°•ë¬¼ê´€', 'ê³µì›', 'gangnam', 'hongdae', 'myeongdong', 'itaewon', 'culture', 'ë¬¸í™”', 'transportation', 'êµí†µ', 'weather', 'ë‚ ì”¨']
            has_advice = any(kw in message_lower for kw in advice_patterns)
            has_place = any(place in message_lower for place in place_keywords)
            
            if has_advice and not has_place:
                return {"type": "general_advice", "keyword": message, "count": extracted_count}
        
        # ì¶”ì²œ ì§ˆë¬¸ ê°ì§€
        recommendation_patterns = ['recommend', 'suggestion', 'suggest', 'ì¶”ì²œ', 'places to visit', 'where to go', 'ê°€ë³¼', 'best places', 'top places', 'ëª…ì†Œ', 'best', 'top', 'popular', 'ì¸ê¸°']
        has_recommendation = any(kw in message_lower for kw in recommendation_patterns)
        
        if has_recommendation or extracted_count:
            return {"type": "recommendation", "keyword": message, "count": extracted_count or 10}
        
        # ê¸°ë³¸ ê²€ìƒ‰
        keyword = ChatService._extract_keyword_simple(message)
        search_type = "kcontent_search" if is_kcontent_mode else "place_search"
        return {"type": search_type, "keyword": keyword, "count": extracted_count}
    
    @staticmethod
    def _extract_keyword_simple(message: str) -> str:
        """í‚¤ì›Œë“œ ì¶”ì¶œ (ë” ë³´ìˆ˜ì ìœ¼ë¡œ)"""
        remove_words = [
            'introduce', 'introduco', 'tell me about', 'what is', 'where is', 'about', 
            'where', 'are'  # ğŸ”§ í•µì‹¬ ë‹¨ì–´ëŠ” ìœ ì§€
        ]
        keyword = message.lower()
        for word in remove_words:
            keyword = keyword.replace(word, '')
        keyword = ' '.join(keyword.split())
        return keyword.strip() if len(keyword.strip()) >= 2 else message
    
    @staticmethod
    def _is_restaurant_query(message: str) -> bool:
        """ë ˆìŠ¤í† ë‘ ê´€ë ¨ ì§ˆë¬¸ íŒë‹¨"""
        restaurant_keywords = ['restaurant', 'food', 'eat', 'dining', 'meal', 'cuisine', 'dish', 'ë ˆìŠ¤í† ë‘', 'ìŒì‹', 'ë¨¹', 'ì‹ë‹¹', 'ë§›ì§‘', 'ìš”ë¦¬', 'ìŒì‹ì ']
        return any(keyword in message.lower() for keyword in restaurant_keywords)
    
    # ===== ì§€ë„ ë§ˆì»¤ =====
    
    @staticmethod
    def _create_markers(results_data: List[Dict]) -> List[Dict]:
        """ì§€ë„ ë§ˆì»¤ ìƒì„± (í†µí•© - K-Content í¬í•¨)"""
        markers = []
        for item in results_data:
            if not item:
                continue
            lat, lng = item.get('latitude', 0.0), item.get('longitude', 0.0)
            
            if lat and lng and lat != 0.0 and lng != 0.0:
                item_type = item.get('type', 'attraction')
                
                # ê¸°ë³¸ ë§ˆì»¤ ì •ë³´
                marker = {
                    "id": item.get('festival_id') or item.get('attr_id') or item.get('content_id') or item.get('id'),
                    "latitude": float(lat),
                    "longitude": float(lng),
                    "type": item_type
                }
                
                # íƒ€ì…ë³„ ì¶”ê°€ ì •ë³´ (K-Content í•„ë“œëª… ë§¤í•‘)
                if item_type == 'restaurant':
                    marker.update({
                        "title": item.get('restaurant_name', ''),
                        "restaurant_id": item.get('id'),
                        "description": item.get('description', ''),
                        "place": item.get('place', ''),
                        "subway": item.get('subway', '')
                    })
                elif item_type == 'festival':
                    marker.update({
                        "title": item.get('title', ''),
                        "festival_id": item['festival_id'],
                        "description": item.get('description', '')[:100] + "...",
                        "image_url": item.get('image_url'),
                        "start_date": item.get('start_date'),
                        "end_date": item.get('end_date')
                    })
                elif item_type == 'kcontent':
                    # ğŸ¬ K-Content ë§ˆì»¤ (í•„ë“œëª… ë§¤í•‘)
                    marker.update({
                        "title": f"{item.get('drama_name')} - {item.get('location_name')}",
                        "content_id": item.get('content_id'),
                        "drama_name": item.get('drama_name'),
                        "location_name": item.get('location_name'),
                        "address": item.get('address'),
                        "thumbnail": item.get('thumbnail'),
                        "trip_tip": item.get('trip_tip', '')[:100] + "..." if item.get('trip_tip') else ""
                    })
                else:  # attraction
                    marker.update({
                        "title": item.get('title', ''),
                        "attr_id": item.get('attr_id'),
                        "address": item.get('address'),
                        "phone": item.get('phone'),
                        "image_urls": item.get('image_urls')
                    })
                
                markers.append(marker)
        
        return markers
    
    # ===== ëœë¤ ì¶”ì²œ =====
    
    @staticmethod
    def _get_random_attractions(count: int = 10) -> List[Dict[str, Any]]:
        """ëœë¤ ê´€ê´‘ëª…ì†Œ ì¶”ì²œ"""
        try:
            print(f"ğŸ² ëœë¤ ê´€ê´‘ëª…ì†Œ {count}ê°œ ì¶”ì²œ ì‹œì‘...")
            
            qdrant_client = ChatService._get_qdrant_client()
            fetch_count = min(count * 5, 100)
            
            scroll_result = qdrant_client.scroll(
                collection_name=ChatService.ATTRACTION_COLLECTION,
                limit=fetch_count,
                offset=random.randint(0, 50),
                with_payload=True,
                with_vectors=False
            )
            
            points = scroll_result[0]
            if not points:
                return []
            
            random.shuffle(points)
            selected_points = points[:count]
            
            attractions = []
            for point in selected_points:
                attraction_data = point.payload.get("metadata", {})
                formatted_data = {
                    "attr_id": attraction_data.get("attr_id"),
                    "title": attraction_data.get("title"),
                    "latitude": float(attraction_data.get("latitude", 0)),
                    "longitude": float(attraction_data.get("longitude", 0)),
                    "type": "attraction"
                }
                attractions.append(formatted_data)
            
            return attractions
            
        except Exception as e:
            print(f"âŒ ëœë¤ ì¶”ì²œ ì˜¤ë¥˜: {e}")
            return []
    
    @staticmethod
    def _get_random_kcontents(count: int = 10) -> List[Dict[str, Any]]:
        """ğŸ¬ ëœë¤ K-Content ì¶”ì²œ"""
        try:
            print(f"ğŸ² ëœë¤ K-Content {count}ê°œ ì¶”ì²œ ì‹œì‘...")
            
            qdrant_client = ChatService._get_qdrant_client()
            fetch_count = min(count * 5, 100)
            
            scroll_result = qdrant_client.scroll(
                collection_name=ChatService.KCONTENT_COLLECTION,
                limit=fetch_count,
                offset=random.randint(0, 50),
                with_payload=True,
                with_vectors=False
            )
            
            points = scroll_result[0]
            if not points:
                return []
            
            random.shuffle(points)
            selected_points = points[:count]
            
            kcontents = []
            for point in selected_points:
                kcontent_metadata = point.payload.get("metadata", {})
                formatted_data = {
                    "content_id": kcontent_metadata.get("content_id"),
                    "drama_name": kcontent_metadata.get("drama_name_ko"),  # ğŸ”„ ë³€ê²½
                    "location_name": kcontent_metadata.get("location_name_en"),  # ğŸ”„ ë³€ê²½
                    "thumbnail": kcontent_metadata.get("thumbnail", ""),
                    "latitude": float(kcontent_metadata.get("latitude", 0)),
                    "longitude": float(kcontent_metadata.get("longitude", 0)),
                    "type": "kcontent"
                }
                kcontents.append(formatted_data)
            
            return kcontents
            
        except Exception as e:
            print(f"âŒ ëœë¤ K-Content ì¶”ì²œ ì˜¤ë¥˜: {e}")
            return []
    
    @staticmethod
    def _generate_random_response(items: List[Dict], is_kcontent: bool = False) -> str:
        """ëœë¤ ì¶”ì²œ ì‘ë‹µ ìƒì„±"""
        if not items:
            if is_kcontent:
                return "Sorry, I couldn't find any K-Drama locations at the moment. ğŸ˜¢"
            return "Hey Hunters! ğŸ˜… ì§€ê¸ˆ ì¶”ì²œí•  ë¯¸ì…˜ ì¥ì†Œê°€ ì—†ë„¤... ë‹¤ì‹œ ê²€ìƒ‰í•´ë³¼ê²Œ! ğŸ”¥"
        
        if is_kcontent:
            return f"ğŸ¬ OMG! Here are {len(items)} amazing K-Drama filming locations in Seoul! Each spot is iconic and perfect for K-Drama fans! Ask me about any specific location for more details! ğŸ’•âœ¨"
        return f"Yo! Hunters! ğŸ”¥ğŸ’« ì—„ì„ í•œ {len(items)}ê°œì˜ ì „ì„¤ì ì¸ ì¥ì†Œë“¤ì´ì•¼! ê° ì¥ì†Œë§ˆë‹¤ íŠ¹ë³„í•œ ë¹›ì˜ ì—ë„ˆì§€ê°€ ìˆìœ¼ë‹ˆê¹Œ ì§ì ‘ ì²´í¬í•´ë´! ê¶ê¸ˆí•œ ê³³ ìˆìœ¼ë©´ ë§í•´ì¤˜! Let's explore! ğŸŒ™âœ¨"
    
    # ===== ë©”ì¸ API í•¨ìˆ˜ (ìŠ¤íŠ¸ë¦¬ë° ì „ìš©) =====
    
    @staticmethod
    async def send_message_streaming(db: Session, user_id: int, message: str, is_kcontent_mode: bool = False):
        """ìŠ¤íŠ¸ë¦¬ë° ë©”ì‹œì§€ ì²˜ë¦¬ (ë‹¤ì¤‘ ê²€ìƒ‰ ê¸°ëŠ¥ + í¬ë§·íŒ… ê°•ì œ)"""
        try:
            # ë¶„ì„
            analysis = ChatService._analyze_message_fast(message, is_kcontent_mode)
            question_type = analysis.get('type', 'place_search')
            keyword = analysis.get('keyword', message)
            is_restaurant_query = ChatService._is_restaurant_query(message)
            
            print(f"ğŸ“‹ ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„: type={question_type}, keyword={keyword}, kcontent={is_kcontent_mode}, restaurant={is_restaurant_query}")
            
            # ğŸ¬ K-Content ëª¨ë“œ ì²˜ë¦¬
            if is_kcontent_mode:
                # ğŸ†• ë‹¤ì¤‘ ê²€ìƒ‰ ì²˜ë¦¬
                if question_type == "multiple_kcontent_search":
                    yield f"data: {json.dumps({'type': 'searching', 'message': 'ğŸ” Finding all filming locations from this drama...'}, ensure_ascii=False)}\n\n"
                    
                    count = analysis.get('count', 20)
                    multiple_kcontents = ChatService._search_multiple_kcontent(keyword, count)
                    
                    if not multiple_kcontents:
                        yield f"data: {json.dumps({'type': 'error', 'message': 'Sorry, I could not find locations for this drama. ğŸ˜…'}, ensure_ascii=False)}\n\n"
                        return
                    
                    # AI ì‘ë‹µ ìƒì„±
                    ai_response = f"ğŸ¬ Amazing! I found {len(multiple_kcontents)} filming locations from this drama! Each place has its own special story. Tap any location card below for detailed information! ğŸ’•âœ¨"
                    
                    # ëŒ€í™” ì €ì¥
                    conversation = Conversation(user_id=user_id, question=message, response=ai_response)
                    db.add(conversation)
                    db.commit()
                    db.refresh(conversation)
                    
                    # ğŸ¨ ì¹´ë“œ í˜•íƒœ ë°ì´í„° ì¤€ë¹„
                    location_cards = []
                    for location in multiple_kcontents:
                        card = {
                            "content_id": location.get('content_id'),
                            "location_name": location.get('location_name'),
                            "category": location.get('category'),
                            "thumbnail": location.get('thumbnail'),
                            "drama_name": location.get('drama_name'),
                            "clickable": True
                        }
                        location_cards.append(card)
                    
                    # ì§€ë„ ë§ˆì»¤ ìƒì„±
                    map_markers = []
                    for location in multiple_kcontents:
                        if location.get('latitude') and location.get('longitude'):
                            marker = {
                                "id": location.get('content_id'),
                                "latitude": location.get('latitude'),
                                "longitude": location.get('longitude'),
                                "title": location.get('location_name'),
                                "category": location.get('category'),
                                "type": "kcontent"
                            }
                            map_markers.append(marker)
                    
                    # ğŸ¯ ìµœì¢… ì‘ë‹µ
                    completion_data = {
                        'type': 'multiple_locations',
                        'full_response': ai_response,
                        'convers_id': conversation.convers_id,
                        'location_cards': location_cards,
                        'total_count': len(multiple_kcontents),
                        'drama_name': multiple_kcontents[0].get('drama_name') if multiple_kcontents else '',
                        'has_kcontents': True,
                        'map_markers': map_markers
                    }
                    
                    yield f"data: {json.dumps(completion_data, ensure_ascii=False)}\n\n"
                    return
                
                # ë¹„êµ ì§ˆë¬¸
                elif question_type == "comparison":
                    yield f"data: {json.dumps({'type': 'generating', 'message': 'ğŸ¤” Comparing K-Drama locations...'}, ensure_ascii=False)}\n\n"
                    
                    prompt = KCONTENT_COMPARISON_PROMPT.format(message=message)
                    
                    # í¬ë§·íŒ… ê°•ì œ!
                    messages = [
                        ChatService.FORMATTING_SYSTEM_MESSAGE,
                        {"role": "user", "content": prompt}
                    ]
                    
                    full_response = ""
                    for chunk in chat_with_gpt_stream(messages, max_tokens=300, temperature=0.7):
                        full_response += chunk
                        yield f"data: {json.dumps({'type': 'chunk', 'content': chunk}, ensure_ascii=False)}\n\n"
                        await asyncio.sleep(0.02)
                    
                    conversation = Conversation(user_id=user_id, question=message, response=full_response)
                    db.add(conversation)
                    db.commit()
                    db.refresh(conversation)
                    
                    yield f"data: {json.dumps({'type': 'done', 'full_response': full_response, 'convers_id': conversation.convers_id, 'kcontents': [], 'has_kcontents': False}, ensure_ascii=False)}\n\n"
                    return
                
                # ì¡°ì–¸ ì§ˆë¬¸
                elif question_type == "general_advice":
                    yield f"data: {json.dumps({'type': 'generating', 'message': 'ğŸ’¡ Preparing K-Drama tips...'}, ensure_ascii=False)}\n\n"
                    
                    prompt = KCONTENT_ADVICE_PROMPT.format(message=message)
                    
                    # í¬ë§·íŒ… ê°•ì œ!
                    messages = [
                        ChatService.FORMATTING_SYSTEM_MESSAGE,
                        {"role": "user", "content": prompt}
                    ]
                    
                    full_response = ""
                    for chunk in chat_with_gpt_stream(messages, max_tokens=350, temperature=0.7):
                        full_response += chunk
                        yield f"data: {json.dumps({'type': 'chunk', 'content': chunk}, ensure_ascii=False)}\n\n"
                        await asyncio.sleep(0.02)
                    
                    conversation = Conversation(user_id=user_id, question=message, response=full_response)
                    db.add(conversation)
                    db.commit()
                    db.refresh(conversation)
                    
                    yield f"data: {json.dumps({'type': 'done', 'full_response': full_response, 'convers_id': conversation.convers_id, 'kcontents': [], 'has_kcontents': False}, ensure_ascii=False)}\n\n"
                    return
                
                # ëœë¤ ì¶”ì²œ
                elif question_type == "recommendation":
                    yield f"data: {json.dumps({'type': 'random', 'message': 'ğŸ² Finding amazing K-Drama locations...'}, ensure_ascii=False)}\n\n"
                    
                    count = analysis.get('count', 10)
                    random_kcontents = ChatService._get_random_kcontents(count)
                    ai_response = ChatService._generate_random_response(random_kcontents, True)
                    
                    conversation = Conversation(user_id=user_id, question=message, response=ai_response)
                    db.add(conversation)
                    db.commit()
                    db.refresh(conversation)
                    
                    map_markers = ChatService._create_markers(random_kcontents)
                    
                    yield f"data: {json.dumps({'type': 'done', 'full_response': ai_response, 'results': random_kcontents, 'kcontents': random_kcontents, 'convers_id': conversation.convers_id, 'has_kcontents': True, 'map_markers': map_markers}, ensure_ascii=False)}\n\n"
                    return
                
                # K-Content ê²€ìƒ‰
                else:
                    yield f"data: {json.dumps({'type': 'searching', 'message': 'ğŸ” Searching for K-Drama location...'}, ensure_ascii=False)}\n\n"
                    
                    kcontent = ChatService._search_best_kcontent(keyword)
                    
                    if not kcontent:
                        yield f"data: {json.dumps({'type': 'error', 'message': 'Sorry, I could not find that K-Drama location. ğŸ˜…'}, ensure_ascii=False)}\n\n"
                        return
                    
                    kcontent['type'] = 'kcontent'
                    title = f"{kcontent['drama_name']} - {kcontent['location_name']}"
                    
                    yield f"data: {json.dumps({'type': 'found', 'title': title, 'result': kcontent}, ensure_ascii=False)}\n\n"
                    yield f"data: {json.dumps({'type': 'generating', 'message': 'ğŸ¬ Preparing K-Drama info...'}, ensure_ascii=False)}\n\n"
                    
                    prompt = KCONTENT_QUICK_PROMPT.format(
                        drama_name=kcontent.get('drama_name', ''),
                        location_name=kcontent.get('location_name', ''),
                        address=kcontent.get('address', ''),
                        trip_tip=kcontent.get('trip_tip', '')[:500],
                        keyword=kcontent.get('keyword', ''),
                        message=message
                    )
                    
                    # í¬ë§·íŒ… ê°•ì œ!
                    messages = [
                        ChatService.FORMATTING_SYSTEM_MESSAGE,
                        {"role": "user", "content": prompt}
                    ]
                    
                    full_response = ""
                    for chunk in chat_with_gpt_stream(messages, max_tokens=250, temperature=0.6):
                        full_response += chunk
                        yield f"data: {json.dumps({'type': 'chunk', 'content': chunk}, ensure_ascii=False)}\n\n"
                        await asyncio.sleep(0.02)
                    
                    conversation = Conversation(user_id=user_id, question=message, response=full_response)
                    db.add(conversation)
                    db.commit()
                    db.refresh(conversation)
                    
                    map_markers = ChatService._create_markers([kcontent])
                    
                    completion_data = {
                        'type': 'done',
                        'full_response': full_response,
                        'convers_id': conversation.convers_id,
                        'result': kcontent,
                        'results': [kcontent],
                        'kcontents': [kcontent],
                        'has_kcontents': True,
                        'map_markers': map_markers
                    }
                    
                    yield f"data: {json.dumps(completion_data, ensure_ascii=False)}\n\n"
                    return
            
            # ğŸ¤ ì¼ë°˜ ëª¨ë“œì—ì„œë„ ë‹¤ì¤‘ ê²€ìƒ‰ í—ˆìš©
            elif question_type == "multiple_kcontent_search":
                yield f"data: {json.dumps({'type': 'searching', 'message': 'ğŸ” Finding all filming locations from this drama...'}, ensure_ascii=False)}\n\n"
                
                count = analysis.get('count', 20)
                multiple_kcontents = ChatService._search_multiple_kcontent(keyword, count)
                
                if not multiple_kcontents:
                    yield f"data: {json.dumps({'type': 'error', 'message': 'Sorry, I could not find locations for this drama. ğŸ˜…'}, ensure_ascii=False)}\n\n"
                    return
                
                ai_response = f"ğŸ¬ Amazing! I found {len(multiple_kcontents)} filming locations from this drama! Each place has its own special story. Tap any location card below for detailed information! ğŸ’•âœ¨"
                
                conversation = Conversation(user_id=user_id, question=message, response=ai_response)
                db.add(conversation)
                db.commit()
                db.refresh(conversation)
                
                location_cards = []
                for location in multiple_kcontents:
                    card = {
                        "content_id": location.get('content_id'),
                        "location_name": location.get('location_name'),
                        "category": location.get('category'),
                        "thumbnail": location.get('thumbnail'),
                        "drama_name": location.get('drama_name'),
                        "clickable": True
                    }
                    location_cards.append(card)
                
                map_markers = []
                for location in multiple_kcontents:
                    if location.get('latitude') and location.get('longitude'):
                        marker = {
                            "id": location.get('content_id'),
                            "latitude": location.get('latitude'),
                            "longitude": location.get('longitude'),
                            "title": location.get('location_name'),
                            "category": location.get('category'),
                            "type": "kcontent"
                        }
                        map_markers.append(marker)
                
                completion_data = {
                    'type': 'multiple_locations',
                    'full_response': ai_response,
                    'convers_id': conversation.convers_id,
                    'location_cards': location_cards,
                    'total_count': len(multiple_kcontents),
                    'drama_name': multiple_kcontents[0].get('drama_name') if multiple_kcontents else '',
                    'has_kcontents': True,
                    'map_markers': map_markers
                }
                
                yield f"data: {json.dumps(completion_data, ensure_ascii=False)}\n\n"
                return
            
            # ğŸ¤ ì¼ë°˜ ëª¨ë“œ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ + í¬ë§·íŒ… ê°•ì œ)
            # ë ˆìŠ¤í† ë‘ ê´€ë ¨ ì²˜ë¦¬
            if is_restaurant_query:
                if question_type == "comparison":
                    yield f"data: {json.dumps({'type': 'generating', 'message': 'ğŸ¤” ë ˆìŠ¤í† ë‘ ë¹„êµ ë¶„ì„ ì¤‘...'}, ensure_ascii=False)}\n\n"
                    
                    prompt = RESTAURANT_COMPARISON_PROMPT.format(message=message)
                    
                    # í¬ë§·íŒ… ê°•ì œ!
                    messages = [
                        ChatService.FORMATTING_SYSTEM_MESSAGE,
                        {"role": "user", "content": prompt}
                    ]
                    
                    full_response = ""
                    for chunk in chat_with_gpt_stream(messages, max_tokens=300, temperature=0.7):
                        full_response += chunk
                        yield f"data: {json.dumps({'type': 'chunk', 'content': chunk}, ensure_ascii=False)}\n\n"
                        await asyncio.sleep(0.02)
                    
                    conversation = Conversation(user_id=user_id, question=message, response=full_response)
                    db.add(conversation)
                    db.commit()
                    db.refresh(conversation)
                    
                    yield f"data: {json.dumps({'type': 'done', 'full_response': full_response, 'convers_id': conversation.convers_id, 'results': [], 'festivals': [], 'attractions': [], 'restaurants': [], 'has_festivals': False, 'has_attractions': False, 'has_restaurants': False}, ensure_ascii=False)}\n\n"
                    return
                
                elif question_type == "general_advice":
                    yield f"data: {json.dumps({'type': 'generating', 'message': 'ğŸ’¡ ìŒì‹ ë¬¸í™” íŒ ì¤€ë¹„ ì¤‘...'}, ensure_ascii=False)}\n\n"
                    
                    prompt = RESTAURANT_ADVICE_PROMPT.format(message=message)
                    
                    # í¬ë§·íŒ… ê°•ì œ!
                    messages = [
                        ChatService.FORMATTING_SYSTEM_MESSAGE,
                        {"role": "user", "content": prompt}
                    ]
                    
                    full_response = ""
                    for chunk in chat_with_gpt_stream(messages, max_tokens=350, temperature=0.7):
                        full_response += chunk
                        yield f"data: {json.dumps({'type': 'chunk', 'content': chunk}, ensure_ascii=False)}\n\n"
                        await asyncio.sleep(0.02)
                    
                    conversation = Conversation(user_id=user_id, question=message, response=full_response)
                    db.add(conversation)
                    db.commit()
                    db.refresh(conversation)
                    
                    yield f"data: {json.dumps({'type': 'done', 'full_response': full_response, 'convers_id': conversation.convers_id, 'results': [], 'festivals': [], 'attractions': [], 'restaurants': [], 'has_festivals': False, 'has_attractions': False, 'has_restaurants': False}, ensure_ascii=False)}\n\n"
                    return
                
                else:
                    # ë ˆìŠ¤í† ë‘ ê²€ìƒ‰
                    yield f"data: {json.dumps({'type': 'searching', 'message': 'ğŸ” ë§›ì§‘ì„ ì°¾ê³  ìˆì–´ìš”...'}, ensure_ascii=False)}\n\n"
                    
                    restaurant = ChatService._search_best_restaurant(keyword)
                    
                    if not restaurant:
                        yield f"data: {json.dumps({'type': 'error', 'message': 'Hey Hunters! ğŸ˜… ê·¸ ë§›ì§‘ì„ ì°¾ì„ ìˆ˜ ì—†ë„¤... ë‹¤ë¥¸ ê³³ì„ ì°¾ì•„ë³´ì! ğŸ”¥'}, ensure_ascii=False)}\n\n"
                        return
                    
                    yield f"data: {json.dumps({'type': 'found', 'title': restaurant['restaurant_name'], 'result': restaurant}, ensure_ascii=False)}\n\n"
                    yield f"data: {json.dumps({'type': 'generating', 'message': 'ğŸ’« ë ˆìŠ¤í† ë‘ ì •ë³´ ìƒì„± ì¤‘...'}, ensure_ascii=False)}\n\n"
                    
                    prompt = RESTAURANT_QUICK_PROMPT.format(
                        restaurant_name=restaurant.get('restaurant_name', ''),
                        location=restaurant.get('place', ''),
                        description=restaurant.get('description', ''),
                        message=message
                    )
                    
                    # í¬ë§·íŒ… ê°•ì œ!
                    messages = [
                        ChatService.FORMATTING_SYSTEM_MESSAGE,
                        {"role": "user", "content": prompt}
                    ]
                    
                    full_response = ""
                    for chunk in chat_with_gpt_stream(messages, max_tokens=250, temperature=0.6):
                        full_response += chunk
                        yield f"data: {json.dumps({'type': 'chunk', 'content': chunk}, ensure_ascii=False)}\n\n"
                        await asyncio.sleep(0.02)
                    
                    conversation = Conversation(user_id=user_id, question=message, response=full_response)
                    db.add(conversation)
                    db.commit()
                    db.refresh(conversation)
                    
                    map_markers = ChatService._create_markers([restaurant])
                    
                    completion_data = {
                        'type': 'done',
                        'full_response': full_response,
                        'convers_id': conversation.convers_id,
                        'result': restaurant,
                        'results': [restaurant],
                        'festivals': [],
                        'attractions': [],
                        'restaurants': [restaurant],
                        'has_festivals': False,
                        'has_attractions': False,
                        'has_restaurants': True,
                        'map_markers': map_markers
                    }
                    
                    yield f"data: {json.dumps(completion_data, ensure_ascii=False)}\n\n"
                    return
            
            # ë¹„êµ ì§ˆë¬¸ ì²˜ë¦¬
            elif question_type == "comparison":
                yield f"data: {json.dumps({'type': 'generating', 'message': 'ğŸ¤” ë¹„êµ ë¶„ì„ ì¤‘...'}, ensure_ascii=False)}\n\n"
                
                prompt = COMPARISON_PROMPT.format(message=message)
                
                # í¬ë§·íŒ… ê°•ì œ!
                messages = [
                    ChatService.FORMATTING_SYSTEM_MESSAGE,
                    {"role": "user", "content": prompt}
                ]
                
                full_response = ""
                for chunk in chat_with_gpt_stream(messages, max_tokens=300, temperature=0.7):
                    full_response += chunk
                    yield f"data: {json.dumps({'type': 'chunk', 'content': chunk}, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(0.02)
                
                conversation = Conversation(user_id=user_id, question=message, response=full_response)
                db.add(conversation)
                db.commit()
                db.refresh(conversation)
                
                yield f"data: {json.dumps({'type': 'done', 'full_response': full_response, 'convers_id': conversation.convers_id, 'results': [], 'festivals': [], 'attractions': [], 'restaurants': [], 'has_festivals': False, 'has_attractions': False, 'has_restaurants': False}, ensure_ascii=False)}\n\n"
                return
            
            # ì¼ë°˜ ì¡°ì–¸ ì§ˆë¬¸ ì²˜ë¦¬
            elif question_type == "general_advice":
                yield f"data: {json.dumps({'type': 'generating', 'message': 'ğŸ’¡ ì—¬í–‰ íŒ ì¤€ë¹„ ì¤‘...'}, ensure_ascii=False)}\n\n"
                
                prompt = ADVICE_PROMPT.format(message=message)
                
                # í¬ë§·íŒ… ê°•ì œ!
                messages = [
                    ChatService.FORMATTING_SYSTEM_MESSAGE,
                    {"role": "user", "content": prompt}
                ]
                
                full_response = ""
                for chunk in chat_with_gpt_stream(messages, max_tokens=350, temperature=0.7):
                    full_response += chunk
                    yield f"data: {json.dumps({'type': 'chunk', 'content': chunk}, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(0.02)
                
                conversation = Conversation(user_id=user_id, question=message, response=full_response)
                db.add(conversation)
                db.commit()
                db.refresh(conversation)
                
                yield f"data: {json.dumps({'type': 'done', 'full_response': full_response, 'convers_id': conversation.convers_id, 'results': [], 'festivals': [], 'attractions': [], 'restaurants': [], 'has_festivals': False, 'has_attractions': False, 'has_restaurants': False}, ensure_ascii=False)}\n\n"
                return
            
            # ëœë¤ ì¶”ì²œ ì²˜ë¦¬
            elif question_type == "recommendation":
                yield f"data: {json.dumps({'type': 'random', 'message': 'ğŸ² ëœë¤ ì¶”ì²œ ì¤€ë¹„ ì¤‘...'}, ensure_ascii=False)}\n\n"
                
                count = analysis.get('count', 10)
                random_attractions = ChatService._get_random_attractions(count)
                ai_response = ChatService._generate_random_response(random_attractions, False)
                
                conversation = Conversation(user_id=user_id, question=message, response=ai_response)
                db.add(conversation)
                db.commit()
                db.refresh(conversation)
                
                yield f"data: {json.dumps({'type': 'done', 'full_response': ai_response, 'results': random_attractions, 'attractions': random_attractions, 'convers_id': conversation.convers_id, 'has_festivals': False, 'has_attractions': True, 'has_restaurants': False, 'map_markers': ChatService._create_markers(random_attractions)}, ensure_ascii=False)}\n\n"
                return
            
            # âœ… ì¼ë°˜ ì¥ì†Œ ê²€ìƒ‰ (ë³‘ë ¬ ì²˜ë¦¬ - K-Content ì¶”ê°€!)
            else:
                yield f"data: {json.dumps({'type': 'searching', 'message': 'ğŸ” ì •ë³´ë¥¼ ì°¾ê³  ìˆì–´ìš”...'}, ensure_ascii=False)}\n\n"
                
                with ThreadPoolExecutor(max_workers=4) as executor:
                    festival_future = executor.submit(ChatService._search_best_festival, keyword)
                    attraction_future = executor.submit(ChatService._search_best_attraction, keyword)
                    restaurant_future = executor.submit(ChatService._search_best_restaurant, keyword)
                    kcontent_future = executor.submit(ChatService._search_best_kcontent, keyword)
                    
                    festival = festival_future.result()
                    attraction = attraction_future.result()
                    restaurant = restaurant_future.result()
                    kcontent = kcontent_future.result()
                
                results = []
                if festival:
                    festival['type'] = 'festival'
                    results.append(festival)
                if attraction:
                    attraction['type'] = 'attraction'
                    results.append(attraction)
                if restaurant:
                    restaurant['type'] = 'restaurant'
                    results.append(restaurant)
                if kcontent:
                    kcontent['type'] = 'kcontent'
                    results.append(kcontent)
                
                if not results:
                    yield f"data: {json.dumps({'type': 'error', 'message': 'Hey Hunters! ğŸ˜… ê·¸ ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ë„¤... ğŸ”¥'}, ensure_ascii=False)}\n\n"
                    return
                
                results.sort(key=lambda x: x['similarity_score'], reverse=True)
                result = results[0]
                
                # ì œëª© ìƒì„±
                if result.get('restaurant_name'):
                    title = result.get('restaurant_name')
                elif result.get('title'):
                    title = result.get('title')
                else:
                    title = f"{result.get('drama_name', 'Unknown')} - {result.get('location_name', 'Unknown')}"
                
                yield f"data: {json.dumps({'type': 'found', 'title': title, 'result': result}, ensure_ascii=False)}\n\n"
                yield f"data: {json.dumps({'type': 'generating', 'message': 'ğŸ’« ì‘ë‹µí•˜ëŠ” ì¤‘...'}, ensure_ascii=False)}\n\n"
                
                # í”„ë¡¬í”„íŠ¸ ìƒì„±
                result_type = result.get('type', 'attraction')
                
                if result_type == 'festival':
                    prompt = KPOP_FESTIVAL_QUICK_PROMPT.format(
                        title=result.get('title', ''),
                        start_date=result.get('start_date', ''),
                        end_date=result.get('end_date', ''),
                        description=result.get('description', '')[:500],
                        message=message
                    )
                elif result_type == 'restaurant':
                    prompt = RESTAURANT_QUICK_PROMPT.format(
                        restaurant_name=result.get('restaurant_name', ''),
                        location=result.get('place', ''),
                        description=result.get('description', ''),
                        message=message
                    )
                elif result_type == 'kcontent':
                    prompt = KCONTENT_QUICK_PROMPT.format(
                        drama_name=result.get('drama_name', ''),
                        location_name=result.get('location_name', ''),
                        address=result.get('address', ''),
                        trip_tip=result.get('trip_tip', '')[:500],
                        keyword=result.get('keyword', ''),
                        message=message
                    )
                else:  # attraction
                    prompt = KPOP_ATTRACTION_QUICK_PROMPT.format(
                        title=result.get('title', ''),
                        address=result.get('address', ''),
                        hours_of_operation=result.get('hours_of_operation', 'ìš´ì˜ì‹œê°„ ì •ë³´ ì—†ìŒ'),
                        description=result.get('description', '')[:500],
                        message=message
                    )
                
                # í¬ë§·íŒ… ê°•ì œ!
                messages = [
                    ChatService.FORMATTING_SYSTEM_MESSAGE,
                    {"role": "user", "content": prompt}
                ]
                
                full_response = ""
                for chunk in chat_with_gpt_stream(messages, max_tokens=250, temperature=0.6):
                    full_response += chunk
                    yield f"data: {json.dumps({'type': 'chunk', 'content': chunk}, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(0.02)
                
                conversation = Conversation(user_id=user_id, question=message, response=full_response)
                db.add(conversation)
                db.commit()
                db.refresh(conversation)
                
                map_markers = ChatService._create_markers([result])
                
                completion_data = {
                    'type': 'done',
                    'full_response': full_response,
                    'convers_id': conversation.convers_id,
                    'result': result,
                    'results': [result],
                    'festivals': [result] if result_type == 'festival' else [],
                    'attractions': [result] if result_type == 'attraction' else [],
                    'restaurants': [result] if result_type == 'restaurant' else [],
                    'kcontents': [result] if result_type == 'kcontent' else [],
                    'has_festivals': result_type == 'festival',
                    'has_attractions': result_type == 'attraction',
                    'has_restaurants': result_type == 'restaurant',
                    'has_kcontents': result_type == 'kcontent',
                    'map_markers': map_markers
                }
                
                yield f"data: {json.dumps(completion_data, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            print(f"âŒ Streaming ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)}, ensure_ascii=False)}\n\n"
    
    # ===== í˜¸í™˜ì„± í•¨ìˆ˜ =====
    
    @staticmethod  
    def send_message(db: Session, user_id: int, message: str, is_kcontent_mode: bool = False) -> Dict[str, Any]:
        """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë™ê¸° wrapper"""
        import asyncio
        
        async def _collect_streaming_result():
            result_data = None
            async for chunk in ChatService.send_message_streaming(db, user_id, message, is_kcontent_mode):
                if '"type": "done"' in chunk or '"type": "multiple_locations"' in chunk:
                    try:
                        data = json.loads(chunk.split('data: ')[1])
                        return data
                    except:
                        pass
            return {"response": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "convers_id": None, "results": []}
        
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(_collect_streaming_result())
    
    @staticmethod
    def get_conversation_history(db: Session, user_id: int, limit: int = 50) -> List[Dict]:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        conversations = db.query(Conversation).filter(
            Conversation.user_id == user_id
        ).order_by(Conversation.datetime.desc()).limit(limit).all()
        
        return [
            {
                "conversation_id": conv.convers_id,
                "message": conv.question,
                "response": conv.response,
                "created_at": conv.datetime.isoformat()
            }
            for conv in reversed(conversations)
        ]