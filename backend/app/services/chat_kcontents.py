# app/services/chat_kcontents.py
"""
ğŸ¬ K-Contents ì „ìš© ì±„íŒ… ì„œë¹„ìŠ¤ (K-Drama/K-Movie ì´¬ì˜ì§€)
- KContents Collectionë§Œ ê²€ìƒ‰
- Festival/Attraction/Restaurant ê²€ìƒ‰ ì•ˆí•¨
- prompt3.py ì‚¬ìš© (ì—´ì •ì ì¸ K-Drama íŒ¬ ê°€ì´ë“œ í†¤)
"""
from typing import Dict, Any, List
from sqlalchemy.orm import Session
import json
import os
import random
import re
import asyncio
from langchain_openai import OpenAIEmbeddings
from qdrant_client import QdrantClient
from concurrent.futures import ThreadPoolExecutor

from app.models.conversation import Conversation  
from app.utils.openai_client import chat_with_gpt, chat_with_gpt_stream
from app.utils.prompt3 import (
    KCONTENT_QUICK_PROMPT,
    KCONTENT_COMPARISON_PROMPT,
    KCONTENT_ADVICE_PROMPT,
    KCONTENT_GENERAL_COMPARISON_PROMPT,
    KCONTENT_GENERAL_ADVICE_PROMPT
)

class ChatKContentsService:
    
    # ğŸ¯ Qdrant ì„¤ì • (KContentsë§Œ)
    QDRANT_URL = "http://172.17.0.1:6333"
    KCONTENT_COLLECTION = "seoul-kcontents"
    
    # ğŸš€ ì„ë² ë”© ëª¨ë¸ ìºì‹± (ì¬ì‚¬ìš©)
    _embedding_model = None
    
    # ğŸš€ Qdrant í´ë¼ì´ì–¸íŠ¸ ìºì‹± (ì¬ì‚¬ìš©)
    _qdrant_client = None
    
    @staticmethod
    def _get_embedding_model():
        """ì„ë² ë”© ëª¨ë¸ ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ì¬ì‚¬ìš©"""
        if ChatKContentsService._embedding_model is None:
            ChatKContentsService._embedding_model = OpenAIEmbeddings(model="text-embedding-ada-002")
        return ChatKContentsService._embedding_model
    
    @staticmethod
    def _get_qdrant_client():
        """Qdrant í´ë¼ì´ì–¸íŠ¸ ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ì¬ì‚¬ìš©"""
        if ChatKContentsService._qdrant_client is None:
            ChatKContentsService._qdrant_client = QdrantClient(
                url=ChatKContentsService.QDRANT_URL,
                timeout=60,
                prefer_grpc=False
            )
        return ChatKContentsService._qdrant_client
    
    # ===== ğŸ”§ ê²€ìƒ‰ì–´ ê°œì„  ê¸°ëŠ¥ =====
    
    @staticmethod
    def _preprocess_query(query: str) -> str:
        """ê²€ìƒ‰ ì „ ì¿¼ë¦¬ ì •ë¦¬"""
        
        # 1. ë¶ˆìš©ì–´ ì œê±°
        stopwords = {"a", "an", "the", "in", "at", "on", "me", "to", "introduce", "tell", "show", "explain", "describe"}
        words = [w for w in query.lower().split() if w not in stopwords]
        
        # 2. ì¬ì¡°í•©
        cleaned_query = " ".join(words)
        
        print(f"ğŸ”§ ì¿¼ë¦¬ ì •ë¦¬: '{query}' â†’ '{cleaned_query}'")
        return cleaned_query if cleaned_query else query
    
    @staticmethod
    def _normalize_query(query: str) -> str:
        """ê²€ìƒ‰ì–´ë¥¼ ì •ê·œí™”í•˜ì—¬ ë” ì •í™•í•œ ë§¤ì¹­ (K-Dramaìš©)"""
        
        # K-Drama/K-Content íŠ¹í™” ë³´ì • ê·œì¹™
        corrections = {
            # ë“œë¼ë§ˆ ì œëª© ì˜ì–´ â†’ í•œê¸€
            "crash landing on you": "ì‚¬ë‘ì˜ ë¶ˆì‹œì°©",
            "itaewon class": "ì´íƒœì› í´ë¼ì“°",
            "kingdom": "í‚¹ë¤",
            "goblin": "ë„ê¹¨ë¹„",
            "descendants of the sun": "íƒœì–‘ì˜ í›„ì˜ˆ",
            "my love from the star": "ë³„ì—ì„œ ì˜¨ ê·¸ëŒ€",
            
            # ì¼ë°˜ ìš©ì–´
            "filming location": "ì´¬ì˜ì§€",
            "drama location": "ë“œë¼ë§ˆ ì´¬ì˜ì§€",
            "kdrama": "í•œêµ­ ë“œë¼ë§ˆ",
            "k-drama": "í•œêµ­ ë“œë¼ë§ˆ",
        }
        
        query_lower = query.lower()
        
        for eng, kor in corrections.items():
            if eng in query_lower:
                query = query.replace(eng, kor)
                print(f"ğŸ”§ ê²€ìƒ‰ì–´ ë³´ì •: '{eng}' â†’ '{kor}'")
        
        return query
    
    @staticmethod
    def _expand_search_terms(query: str) -> List[str]:
        """ê²€ìƒ‰ì–´ë¥¼ ìë™ìœ¼ë¡œ í™•ì¥ (K-Dramaìš©)"""
        
        variants = [query]
        
        # ìë™ ë³€í˜• ê·œì¹™ë“¤
        query_lower = query.lower()
        
        # ì´¬ì˜ì§€ ê´€ë ¨ ë³€í˜•
        if "filming" in query_lower or "location" in query_lower:
            variants.append(query.replace("filming location", "ì´¬ì˜ì§€"))
            variants.append(query.replace("location", "ì¥ì†Œ"))
        
        # ë“œë¼ë§ˆ ê´€ë ¨ ë³€í˜•
        if "drama" in query_lower:
            variants.append(query.replace("drama", "ë“œë¼ë§ˆ"))
        
        return list(set(variants))  # ì¤‘ë³µ ì œê±°
    
    @staticmethod
    def _calculate_keyword_overlap(query: str, title: str) -> float:
        """í‚¤ì›Œë“œ ê²¹ì¹˜ëŠ” ì •ë„ ê³„ì‚°"""
        query_words = set(query.lower().split())
        title_words = set(title.lower().split())
        
        overlap = len(query_words & title_words)
        total = len(query_words | title_words)
        
        return overlap / total if total > 0 else 0
    
    @staticmethod
    def _improved_search(query: str) -> Dict[str, Any]:
        """ğŸ”§ í˜„ì‹¤ì ìœ¼ë¡œ ê°œì„ ëœ K-Content ê²€ìƒ‰"""
        
        try:
            print(f"ğŸ” K-Content ê²€ìƒ‰ ì‹œì‘: '{query}'")
            
            # 1. ì¿¼ë¦¬ ì „ì²˜ë¦¬ (ë¶ˆìš©ì–´ ì œê±°)
            cleaned_query = ChatKContentsService._preprocess_query(query)
            
            # 2. ê²€ìƒ‰ì–´ ì •ê·œí™”
            normalized_query = ChatKContentsService._normalize_query(cleaned_query)
            
            # 3. ê²€ìƒ‰ì–´ í™•ì¥
            search_variants = ChatKContentsService._expand_search_terms(normalized_query)
            print(f"ğŸ”§ ê²€ìƒ‰ ë³€í˜•ë“¤: {search_variants}")
            
            # 4. ëª¨ë“  ë³€í˜•ìœ¼ë¡œ ê²€ìƒ‰
            best_result = None
            best_score = 0
            
            qdrant_client = ChatKContentsService._get_qdrant_client()
            embedding_model = ChatKContentsService._get_embedding_model()
            
            for variant in search_variants:
                try:
                    query_embedding = embedding_model.embed_query(variant)
                    
                    search_results = qdrant_client.search(
                        collection_name=ChatKContentsService.KCONTENT_COLLECTION,
                        query_vector=query_embedding,
                        limit=5,
                        score_threshold=0.3,  # ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ë” ë§ì€ ê²°ê³¼
                        with_payload=True,
                        with_vectors=False
                    )
                    
                    for result in search_results:
                        # Vector ìœ ì‚¬ë„ + í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
                        vector_score = result.score
                        
                        # ğŸ¯ metadataì—ì„œ drama_nameìœ¼ë¡œ ì œëª© ì¶”ì¶œ
                        metadata = result.payload.get("metadata", {})
                        drama_name = metadata.get("drama_name", "")
                        location_name = metadata.get("location_name", "")
                        combined_title = f"{drama_name} {location_name}"
                        
                        keyword_score = ChatKContentsService._calculate_keyword_overlap(cleaned_query, combined_title)
                        combined_score = vector_score * 0.8 + keyword_score * 0.2
                        
                        if combined_score > best_score:
                            best_score = combined_score
                            best_result = result
                            print(f"âœ… ë” ì¢‹ì€ ê²°ê³¼: '{variant}' â†’ ì ìˆ˜: {combined_score:.3f}")
                
                except Exception as e:
                    print(f"âš ï¸ ë³€í˜• '{variant}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    continue
            
            # 5. ê²°ê³¼ ë°˜í™˜ (ì„ê³„ê°’ 0.4ë¡œ ë‚®ì¶¤)
            if best_result and best_score > 0.4:
                return best_result
            else:
                print(f"âŒ ìœ íš¨í•œ ê²°ê³¼ ì—†ìŒ (ìµœê³  ì ìˆ˜: {best_score:.3f})")
                return None
                
        except Exception as e:
            print(f"âŒ K-Content ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    # ===== ğŸ¬ K-Content ê²€ìƒ‰ í•¨ìˆ˜ =====
    
    @staticmethod
    def _search_best_kcontent(keyword: str) -> Dict[str, Any]:
        """ğŸ¬ K-Content ë²¡í„° ê²€ìƒ‰"""
        try:
            print(f"ğŸ¬ K-Content ê²€ìƒ‰: '{keyword}'")
            
            result = ChatKContentsService._improved_search(keyword)
            
            if not result:
                print(f"ğŸ” K-Content ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: '{keyword}'")
                return None
            
            # ğŸ¯ payload.metadataì—ì„œ ë°ì´í„° ì¶”ì¶œ
            kcontent_metadata = result.payload.get("metadata", {})
            
            formatted_data = {
                "content_id": kcontent_metadata.get("content_id", ""),
                "drama_name": kcontent_metadata.get("drama_name", ""),
                "drama_name_en": kcontent_metadata.get("drama_name_en", ""),
                "location_name": kcontent_metadata.get("location_name", ""),
                "location_name_en": kcontent_metadata.get("location_name_en", ""),
                "address": kcontent_metadata.get("address", ""),
                "address_en": kcontent_metadata.get("address_en", ""),
                "trip_tip": kcontent_metadata.get("trip_tip", ""),
                "trip_tip_en": kcontent_metadata.get("trip_tip_en", ""),
                "keyword": kcontent_metadata.get("keyword", ""),
                "keyword_en": kcontent_metadata.get("keyword_en", ""),
                "category": kcontent_metadata.get("category", ""),
                "category_en": kcontent_metadata.get("category_en", ""),
                "thumbnail": kcontent_metadata.get("thumbnail", ""),  # ğŸ¯ ë©”ì¸ ì´ë¯¸ì§€
                "image_url": kcontent_metadata.get("image_url", ""),
                "latitude": float(kcontent_metadata.get("latitude", 0)),
                "longitude": float(kcontent_metadata.get("longitude", 0)),
                "similarity_score": result.score,
                "type": "kcontent"
            }
            
            print(f"ğŸ¯ K-Content ê²€ìƒ‰ ì„±ê³µ: '{formatted_data['drama_name']}' at '{formatted_data['location_name']}' (ìœ ì‚¬ë„: {result.score:.3f})")
            return formatted_data
            
        except Exception as e:
            print(f"K-Content ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    # ===== ë©”ì¸ ë©”ì‹œì§€ ì²˜ë¦¬ í•¨ìˆ˜ =====
    
    @staticmethod
    def send_message(db: Session, user_id: int, message: str) -> Dict[str, Any]:
        """
        ğŸš€ K-Content ë©”ì‹œì§€ ì²˜ë¦¬
        """
        import time
        
        try:
            total_start = time.time()
            
            print(f"ğŸ¬ K-Content ì„œë¹„ìŠ¤ ìš”ì²­: '{message}'")
            
            # ğŸš€ 1. ë¹ ë¥¸ í‚¤ì›Œë“œ ì¶”ì¶œ + ì§ˆë¬¸ íƒ€ì… ë¶„ë¥˜
            step_start = time.time()
            analysis = ChatKContentsService._analyze_message_fast(message)
            print(f"â±ï¸ 1. í‚¤ì›Œë“œ ì¶”ì¶œ: {time.time() - step_start:.3f}ì´ˆ")
            
            question_type = analysis.get('type', 'kcontent_search')
            keyword = analysis.get('keyword', message)
            is_random = analysis.get('is_random_recommendation', False)
            
            # ===== ì§ˆë¬¸ íƒ€ì…ë³„ ì²˜ë¦¬ =====
            
            # ğŸ¤” ë¹„êµ ì§ˆë¬¸ ì²˜ë¦¬
            if question_type == "comparison":
                print(f"ğŸ¤” ë¹„êµ ì§ˆë¬¸ ê°ì§€ â†’ GPT ì§ì ‘ ì²˜ë¦¬")
                
                prompt = KCONTENT_COMPARISON_PROMPT.format(message=message)
                
                ai_response = chat_with_gpt(
                    [{"role": "user", "content": prompt}],
                    max_tokens=300,
                    temperature=0.7
                )
                
                conversation = Conversation(
                    user_id=user_id,
                    question=message,
                    response=ai_response
                )
                db.add(conversation)
                db.commit()
                db.refresh(conversation)
                
                print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {time.time() - total_start:.3f}ì´ˆ\n")
                
                return {
                    "response": ai_response,
                    "convers_id": conversation.convers_id,
                    "kcontents": [],
                    "has_kcontents": False,
                    "map_markers": []
                }
            
            # ğŸ’¡ ì¼ë°˜ ì¡°ì–¸/íŒ ì§ˆë¬¸ ì²˜ë¦¬
            elif question_type == "general_advice":
                print(f"ğŸ’¡ ì¡°ì–¸ ì§ˆë¬¸ ê°ì§€ â†’ GPT ì§ì ‘ ì²˜ë¦¬")
                
                prompt = KCONTENT_ADVICE_PROMPT.format(message=message)
                
                ai_response = chat_with_gpt(
                    [{"role": "user", "content": prompt}],
                    max_tokens=350,
                    temperature=0.7
                )
                
                conversation = Conversation(
                    user_id=user_id,
                    question=message,
                    response=ai_response
                )
                db.add(conversation)
                db.commit()
                db.refresh(conversation)
                
                print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {time.time() - total_start:.3f}ì´ˆ\n")
                
                return {
                    "response": ai_response,
                    "convers_id": conversation.convers_id,
                    "kcontents": [],
                    "has_kcontents": False,
                    "map_markers": []
                }
            
            # ğŸ¯ ëœë¤ ì¶”ì²œ ì²˜ë¦¬
            elif is_random or question_type == "random_recommendation":
                print(f"ğŸ¯ ì¶”ì²œ ì§ˆë¬¸ ê°ì§€ â†’ ìˆ˜ëŸ‰ ê¸°ë°˜ ì¶”ì²œ")
                
                count = analysis.get('count', 10)
                random_kcontents = ChatKContentsService._get_random_kcontents(count=count)
                
                ai_response = ChatKContentsService._generate_random_response(random_kcontents)
                
                conversation = Conversation(
                    user_id=user_id,
                    question=message,
                    response=ai_response
                )
                db.add(conversation)
                db.commit()
                db.refresh(conversation)
                
                print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {time.time() - total_start:.3f}ì´ˆ\n")
                
                return {
                    "response": ai_response,
                    "convers_id": conversation.convers_id,
                    "results": random_kcontents,
                    "kcontents": random_kcontents,
                    "has_kcontents": len(random_kcontents) > 0,
                    "map_markers": ChatKContentsService._create_map_markers(random_kcontents)
                }
            
            # ğŸš€ íŠ¹ì • K-Content ê²€ìƒ‰ (ê¸°ë³¸ ë™ì‘)
            else:
                # ğŸš€ 2. K-Content ê²€ìƒ‰
                step_start = time.time()
                kcontent = ChatKContentsService._search_best_kcontent(keyword)
                print(f"â±ï¸ 2. K-Content ê²€ìƒ‰: {time.time() - step_start:.3f}ì´ˆ")
                
                # ê²°ê³¼ ì²˜ë¦¬
                if kcontent:
                    kcontent['type'] = 'kcontent'
                    best_result = [kcontent]
                else:
                    best_result = []
                
                # ğŸš€ 3. ì‘ë‹µ ìƒì„±
                step_start = time.time()
                ai_response = ChatKContentsService._generate_final_response(message, best_result)
                print(f"â±ï¸ 3. ì‘ë‹µ ìƒì„±: {time.time() - step_start:.3f}ì´ˆ")
                
                # 4. DB ì €ì¥
                step_start = time.time()
                conversation = Conversation(
                    user_id=user_id,
                    question=message,
                    response=ai_response
                )
                db.add(conversation)
                db.commit()
                db.refresh(conversation)
                print(f"â±ï¸ 4. DB ì €ì¥: {time.time() - step_start:.3f}ì´ˆ")
                
                print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {time.time() - total_start:.3f}ì´ˆ\n")
                
                # ğŸ—ºï¸ ì§€ë„ ë§ˆì»¤ ìƒì„±
                map_markers = []
                if best_result:
                    map_markers = ChatKContentsService._create_map_markers(best_result)
                
                # 5. ì‘ë‹µ êµ¬ì„±
                return {
                    "response": ai_response,
                    "convers_id": conversation.convers_id,
                    "results": best_result,
                    "kcontents": best_result,
                    "has_kcontents": len(best_result) > 0,
                    "map_markers": map_markers
                }
            
        except Exception as e:
            raise Exception(f"K-Content ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    @staticmethod
    async def send_message_streaming(db: Session, user_id: int, message: str):
        """
        ğŸŒŠ K-Content ìŠ¤íŠ¸ë¦¬ë° ë©”ì‹œì§€ ì²˜ë¦¬ - ì œë„ˆë ˆì´í„° ë°˜í™˜
        """
        try:
            # ğŸš€ 1. ì§ˆë¬¸ íƒ€ì… ë¶„ì„
            analysis = ChatKContentsService._analyze_message_fast(message)
            question_type = analysis.get('type', 'kcontent_search')
            keyword = analysis.get('keyword', message)
            is_random = analysis.get('is_random_recommendation', False)
            
            print(f"ğŸ“‹ K-Content ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„: type={question_type}, keyword={keyword}")
            
            # ===== ì§ˆë¬¸ íƒ€ì…ë³„ ì²˜ë¦¬ =====
            
            # ğŸ¤” ë¹„êµ ì§ˆë¬¸ ì²˜ë¦¬
            if question_type == "comparison":
                yield f"data: {json.dumps({'type': 'generating', 'message': 'ğŸ¤” Comparing K-Drama locations...'}, ensure_ascii=False)}\n\n"
                
                prompt = KCONTENT_COMPARISON_PROMPT.format(message=message)
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
                full_response = ""
                for chunk in chat_with_gpt_stream([{"role": "user", "content": prompt}], max_tokens=300, temperature=0.7):
                    full_response += chunk
                    yield f"data: {json.dumps({'type': 'chunk', 'content': chunk}, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(0.02)
                
                # ëŒ€í™” ì €ì¥
                conversation = Conversation(user_id=user_id, question=message, response=full_response)
                db.add(conversation)
                db.commit()
                db.refresh(conversation)
                
                yield f"data: {json.dumps({'type': 'done', 'full_response': full_response, 'convers_id': conversation.convers_id, 'kcontents': [], 'has_kcontents': False}, ensure_ascii=False)}\n\n"
                return
            
            # ğŸ’¡ ì¼ë°˜ ì¡°ì–¸/íŒ ì§ˆë¬¸ ì²˜ë¦¬
            elif question_type == "general_advice":
                yield f"data: {json.dumps({'type': 'generating', 'message': 'ğŸ’¡ Preparing K-Drama tips...'}, ensure_ascii=False)}\n\n"
                
                prompt = KCONTENT_ADVICE_PROMPT.format(message=message)
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
                full_response = ""
                for chunk in chat_with_gpt_stream([{"role": "user", "content": prompt}], max_tokens=350, temperature=0.7):
                    full_response += chunk
                    yield f"data: {json.dumps({'type': 'chunk', 'content': chunk}, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(0.02)
                
                # ëŒ€í™” ì €ì¥
                conversation = Conversation(user_id=user_id, question=message, response=full_response)
                db.add(conversation)
                db.commit()
                db.refresh(conversation)
                
                yield f"data: {json.dumps({'type': 'done', 'full_response': full_response, 'convers_id': conversation.convers_id, 'kcontents': [], 'has_kcontents': False}, ensure_ascii=False)}\n\n"
                return
            
            # ğŸ¯ ëœë¤ ì¶”ì²œ ì²˜ë¦¬
            elif is_random or question_type == "random_recommendation":
                yield f"data: {json.dumps({'type': 'random', 'message': 'ğŸ² Finding amazing K-Drama locations...'}, ensure_ascii=False)}\n\n"
                
                random_kcontents = ChatKContentsService._get_random_kcontents(count=10)
                ai_response = ChatKContentsService._generate_random_response(random_kcontents)
                
                # ëŒ€í™” ì €ì¥
                conversation = Conversation(user_id=user_id, question=message, response=ai_response)
                db.add(conversation)
                db.commit()
                db.refresh(conversation)
                
                # ğŸ—ºï¸ ëœë¤ ì¶”ì²œ ë§ˆì»¤ ë””ë²„ê¹…
                print(f"ğŸ—ºï¸ ëœë¤ ë§ˆì»¤ ìƒì„± ì‹œì‘: kcontents ê°œìˆ˜={len(random_kcontents)}")
                map_markers = ChatKContentsService._create_map_markers(random_kcontents)
                print(f"ğŸ—ºï¸ ëœë¤ ìƒì„±ëœ ë§ˆì»¤: {len(map_markers)}ê°œ")
                
                yield f"data: {json.dumps({'type': 'done', 'full_response': ai_response, 'results': random_kcontents, 'kcontents': random_kcontents, 'convers_id': conversation.convers_id, 'has_kcontents': True, 'map_markers': map_markers}, ensure_ascii=False)}\n\n"
                return
            
            # ğŸš€ íŠ¹ì • K-Content ê²€ìƒ‰ (ê¸°ë³¸ ë™ì‘)
            else:
                yield f"data: {json.dumps({'type': 'searching', 'message': 'ğŸ” Searching for K-Drama location...'}, ensure_ascii=False)}\n\n"
                
                # K-Content ê²€ìƒ‰
                kcontent = ChatKContentsService._search_best_kcontent(keyword)
                
                if not kcontent:
                    yield f"data: {json.dumps({'type': 'error', 'message': 'Sorry, I could not find that K-Drama location. ğŸ˜…'}, ensure_ascii=False)}\n\n"
                    return
                
                kcontent['type'] = 'kcontent'
                
                title = f"{kcontent['drama_name']} - {kcontent['location_name']}"
                yield f"data: {json.dumps({'type': 'found', 'title': title, 'result': kcontent}, ensure_ascii=False)}\n\n"
                
                yield f"data: {json.dumps({'type': 'generating', 'message': 'ğŸ¬ Preparing K-Drama info...'}, ensure_ascii=False)}\n\n"
                
                # í”„ë¡¬í”„íŠ¸ ìƒì„±
                prompt = KCONTENT_QUICK_PROMPT.format(
                    drama_name=kcontent.get('drama_name', ''),
                    location_name=kcontent.get('location_name', ''),
                    address=kcontent.get('address', ''),
                    trip_tip=kcontent.get('trip_tip', '')[:500],
                    keyword=kcontent.get('keyword', ''),
                    message=message
                )
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
                full_response = ""
                for chunk in chat_with_gpt_stream([{"role": "user", "content": prompt}], max_tokens=250, temperature=0.6):
                    full_response += chunk
                    yield f"data: {json.dumps({'type': 'chunk', 'content': chunk}, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(0.02)
                
                # ëŒ€í™” ì €ì¥
                conversation = Conversation(user_id=user_id, question=message, response=full_response)
                db.add(conversation)
                db.commit()
                db.refresh(conversation)
                
                # ğŸ—ºï¸ ì§€ë„ ë§ˆì»¤ ìƒì„± - ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€!
                print(f"ğŸ—ºï¸ ë§ˆì»¤ ìƒì„± ì‹œì‘: kcontent ë°ì´í„° í™•ì¸")
                print(f"  - drama_name: {kcontent.get('drama_name', 'MISSING')}")
                print(f"  - location_name: {kcontent.get('location_name', 'MISSING')}")
                print(f"  - latitude: {kcontent.get('latitude', 'MISSING')}")
                print(f"  - longitude: {kcontent.get('longitude', 'MISSING')}")
                print(f"  - content_id: {kcontent.get('content_id', 'MISSING')}")
                
                map_markers = ChatKContentsService._create_map_markers([kcontent])
                print(f"ğŸ—ºï¸ ìƒì„±ëœ ë§ˆì»¤ ê²°ê³¼:")
                print(f"  - ë§ˆì»¤ ê°œìˆ˜: {len(map_markers)}")
                print(f"  - ë§ˆì»¤ ë°ì´í„°: {map_markers}")
                
                # ì™„ë£Œ ë©”ì‹œì§€
                completion_data = {
                    'type': 'done',
                    'full_response': full_response,
                    'convers_id': conversation.convers_id,
                    'result': kcontent,
                    'results': [kcontent],
                    'kcontents': [kcontent],
                    'has_kcontents': True,
                    'map_markers': map_markers
                }
                
                print(f"ğŸ—ºï¸ ì™„ë£Œ ë°ì´í„° ì „ì†¡: map_markers={len(map_markers)}ê°œ")
                yield f"data: {json.dumps(completion_data, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            print(f"âŒ K-Content Streaming ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)}, ensure_ascii=False)}\n\n"
    
    # ===== ğŸ”§ í—¬í¼ í•¨ìˆ˜ë“¤ =====
    
    @staticmethod
    def _analyze_message_fast(message: str) -> Dict[str, Any]:
        """
        ğŸš€ ì´ˆê³ ì† í‚¤ì›Œë“œ ë¶„ì„ - K-Content ì§ˆë¬¸ íƒ€ì… ìë™ ë¶„ë¥˜
        """
        try:
            message_lower = message.lower().strip()
            
            print(f"\nğŸ” K-Content ì§ˆë¬¸ ë¶„ì„ ì‹œì‘: '{message}'")
            
            # === ìˆ˜ëŸ‰ ì¶”ì¶œ ===
            import re
            number_patterns = [
                r'(\d+)ê³³', r'(\d+)ê°œ', r'(\d+)ê°€ì§€',
                r'(\d+)\s*places?', r'(\d+)\s*spots?', r'(\d+)\s*locations?'
            ]
            
            extracted_count = None
            for pattern in number_patterns:
                match = re.search(pattern, message_lower)
                if match:
                    extracted_count = int(match.group(1))
                    print(f"   âœ… ìˆ˜ëŸ‰ ë°œê²¬: {extracted_count}ê°œ")
                    break
            
            # === ë¹„êµ ì§ˆë¬¸ ê°ì§€ ===
            comparison_patterns = [
                ' vs ', 'vs.', ' versus ', 'which one', 'which is better', 'compare'
            ]
            for pattern in comparison_patterns:
                if pattern in message_lower:
                    return {
                        "type": "comparison",
                        "keyword": message,
                        "count": extracted_count
                    }
            
            # === ì¼ë°˜ ì¡°ì–¸/íŒ ì§ˆë¬¸ ê°ì§€ ===
            advice_patterns = [
                'tip', 'tips', 'advice', 'íŒ', 'ì¡°ì–¸',
                'how to', 'ì–´ë–»ê²Œ', 'ë°©ë²•',
                'what should i know', 'ì•Œì•„ì•¼', 'ì¤€ë¹„',
                'etiquette', 'ì—í‹°ì¼“', 'visit', 'ë°©ë¬¸'
            ]
            
            has_advice_keyword = any(kw in message_lower for kw in advice_patterns)
            
            # K-Drama ê´€ë ¨ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì¡°ì–¸ ì§ˆë¬¸
            drama_keywords = [
                'drama', 'filming', 'location', 'scene',
                'ë“œë¼ë§ˆ', 'ì´¬ì˜ì§€', 'ì¥ë©´', 'ì¥ì†Œ'
            ]
            has_drama = any(kw in message_lower for kw in drama_keywords)
            
            if has_advice_keyword and not has_drama:
                return {
                    "type": "general_advice",
                    "keyword": message,
                    "count": extracted_count
                }
            
            # === ì¶”ì²œ ì§ˆë¬¸ ê°ì§€ ===
            recommendation_patterns = [
                'recommend', 'suggestion', 'suggest', 'ì¶”ì²œ',
                'best', 'top', 'popular', 'ì¸ê¸°'
            ]
            
            has_recommendation = any(kw in message_lower for kw in recommendation_patterns)
            
            if has_recommendation or extracted_count:
                return {
                    "type": "recommendation",
                    "keyword": message,
                    "count": extracted_count or 10
                }
            
            # === íŠ¹ì • K-Content ê²€ìƒ‰ (ê¸°ë³¸) ===
            keyword = ChatKContentsService._extract_keyword_simple(message)
            return {
                "type": "kcontent_search",
                "keyword": keyword,
                "count": extracted_count
            }
            
        except Exception as e:
            print(f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {
                "type": "kcontent_search",
                "keyword": message,
                "count": None
            }

    @staticmethod
    def _extract_keyword_simple(message: str) -> str:
        """ğŸš€ ë‹¨ìˆœ í‚¤ì›Œë“œ ì¶”ì¶œ (GPT ì—†ì´)"""
        remove_words = [
            'introduce', 'introduco', 'tell me about', 'what is', 'where is',
            'about', 'the', 'a', 'an', 'me', 'filming', 'location'
        ]
        
        keyword = message.lower()
        for word in remove_words:
            keyword = keyword.replace(word, '')
        
        keyword = ' '.join(keyword.split())
        
        if len(keyword.strip()) < 2:
            keyword = message
        
        return keyword.strip()
    
    @staticmethod
    def _get_random_kcontents(count: int = 10) -> List[Dict[str, Any]]:
        """ğŸ¯ ëœë¤ K-Content ì¶”ì²œ"""
        try:
            print(f"ğŸ² ëœë¤ K-Content {count}ê°œ ì¶”ì²œ ì‹œì‘...")
            
            qdrant_client = ChatKContentsService._get_qdrant_client()
            
            fetch_count = min(count * 5, 100)
            
            scroll_result = qdrant_client.scroll(
                collection_name=ChatKContentsService.KCONTENT_COLLECTION,
                limit=fetch_count,
                offset=random.randint(0, 50),
                with_payload=True,
                with_vectors=False
            )
            
            points = scroll_result[0]
            
            if not points:
                print(f"âŒ K-Contentë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            print(f"ğŸ“Š ê°€ì ¸ì˜¨ K-Content: {len(points)}ê°œ")
            
            random.shuffle(points)
            selected_points = points[:count]
            
            kcontents = []
            for point in selected_points:
                # ğŸ¯ payload.metadataì—ì„œ ë°ì´í„° ì¶”ì¶œ
                kcontent_metadata = point.payload.get("metadata", {})
                
                formatted_data = {
                    "content_id": kcontent_metadata.get("content_id"),
                    "drama_name": kcontent_metadata.get("drama_name"),
                    "location_name": kcontent_metadata.get("location_name"),
                    "thumbnail": kcontent_metadata.get("thumbnail", ""),
                    "latitude": float(kcontent_metadata.get("latitude", 0)),
                    "longitude": float(kcontent_metadata.get("longitude", 0)),
                    "type": "kcontent"
                }
                
                kcontents.append(formatted_data)
                print(f"  âœ… {formatted_data['drama_name']} - {formatted_data['location_name']}")
            
            print(f"ğŸ² ëœë¤ ì¶”ì²œ ì™„ë£Œ: {len(kcontents)}ê°œ")
            return kcontents
            
        except Exception as e:
            print(f"âŒ ëœë¤ ì¶”ì²œ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    @staticmethod
    def _generate_random_response(kcontents: List[Dict]) -> str:
        """ğŸ¯ ëœë¤ ì¶”ì²œ ì‘ë‹µ ìƒì„±"""
        if not kcontents:
            return "Sorry, I couldn't find any K-Drama locations at the moment. ğŸ˜¢"
        
        return f"ğŸ¬ OMG! Here are {len(kcontents)} amazing K-Drama filming locations in Seoul! Each spot is iconic and perfect for K-Drama fans! Ask me about any specific location for more details! ğŸ’•âœ¨"
    
    @staticmethod
    def _create_map_markers(kcontents_data: List[Dict]) -> List[Dict]:
        """ì§€ë„ ë§ˆì»¤ ë°ì´í„° ìƒì„± (K-Content) - ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€"""
        print(f"ğŸ—ºï¸ _create_map_markers í˜¸ì¶œ: ì…ë ¥ ë°ì´í„° {len(kcontents_data)}ê°œ")
        
        markers = []
        for i, item in enumerate(kcontents_data):
            print(f"ğŸ—ºï¸ ë§ˆì»¤ {i+1} ì²˜ë¦¬ ì¤‘:")
            print(f"  - item íƒ€ì…: {type(item)}")
            print(f"  - item í‚¤ë“¤: {list(item.keys()) if isinstance(item, dict) else 'NOT DICT'}")
            
            lat = item.get('latitude', 0.0)
            lng = item.get('longitude', 0.0)
            
            print(f"  - ì¢Œí‘œ: lat={lat}, lng={lng}")
            print(f"  - ì¢Œí‘œ íƒ€ì…: lat={type(lat)}, lng={type(lng)}")
            print(f"  - ì¢Œí‘œ ìœ íš¨ì„±: lat != 0.0 = {lat != 0.0}, lng != 0.0 = {lng != 0.0}")
            
            if lat and lng and lat != 0.0 and lng != 0.0:
                marker = {
                    "id": item.get('content_id'),
                    "title": f"{item.get('drama_name')} - {item.get('location_name')}",
                    "latitude": float(lat),
                    "longitude": float(lng),
                    "type": "kcontent",
                    "content_id": item.get('content_id'),
                    "drama_name": item.get('drama_name'),
                    "location_name": item.get('location_name'),
                    "address": item.get('address'),
                    "thumbnail": item.get('thumbnail'),
                    "trip_tip": item.get('trip_tip', '')[:100] + "..."
                }
                
                markers.append(marker)
                print(f"  âœ… ë§ˆì»¤ {i+1} ìƒì„± ì„±ê³µ: {marker['title']}")
            else:
                print(f"  âŒ ë§ˆì»¤ {i+1} ìŠ¤í‚µ: ì¢Œí‘œ ë¬´íš¨ (lat={lat}, lng={lng})")
        
        print(f"ğŸ—ºï¸ _create_map_markers ì™„ë£Œ: ì´ {len(markers)}ê°œ ë§ˆì»¤ ìƒì„±")
        return markers
    
    @staticmethod
    def _generate_final_response(message: str, kcontents_data: List[Dict]) -> str:
        """ğŸ¬ ìµœì¢… ì‘ë‹µ ìƒì„± (K-Content)"""
        try:
            if not kcontents_data:
                return "Hey K-Drama fan! ğŸ¬ Ask me about any filming location in Seoul and I'll share all the exciting details! ğŸ’•"
            
            kcontent = kcontents_data[0]
            
            print(f"ğŸ¬ GPT ì‘ë‹µ ìƒì„± (K-Content)")
            return ChatKContentsService._gpt_response(message, kcontent)
                
        except Exception as e:
            print(f"âŒ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            if kcontents_data:
                kcontent = kcontents_data[0]
                return f"ğŸ¬ Found the filming location for {kcontent.get('drama_name')}! Check the details below ğŸ’•"
            else:
                return "Hey K-Drama fan! ğŸ¬ Ask me anything! ğŸ˜Š"
    
    @staticmethod
    def _gpt_response(message: str, kcontent: Dict) -> str:
        """ğŸ¬ K-Content GPT ì‘ë‹µ"""
        prompt = KCONTENT_QUICK_PROMPT.format(
            drama_name=kcontent.get('drama_name', ''),
            location_name=kcontent.get('location_name', ''),
            address=kcontent.get('address', ''),
            trip_tip=kcontent.get('trip_tip', '')[:500],
            keyword=kcontent.get('keyword', ''),
            message=message
        )
        
        response_messages = [{"role": "user", "content": prompt}]
        
        return chat_with_gpt(response_messages, max_tokens=250, temperature=0.6)
    
    @staticmethod
    def get_conversation_history(db: Session, user_id: int, limit: int = 50) -> List[Dict]:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        conversations = db.query(Conversation).filter(
            Conversation.user_id == user_id
        ).order_by(Conversation.datetime.desc()).limit(limit).all()
        
        return [
            {
                "conversation_id": conv.convers_id,
                "message": conv.question,
                "response": conv.response,
                "created_at": conv.datetime.isoformat()
            }
            for conv in reversed(conversations)
        ]